{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrIj1b3BMWxm",
        "outputId": "efe150a2-ed34-432f-f7e5-acf9e35dc4f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymongo\n",
            "  Downloading pymongo-4.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Downloading pymongo-4.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.7.0 pymongo-4.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pymongo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "621OAEcU3QY6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pymongo\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "c4STbPMO3TcJ"
      },
      "outputs": [],
      "source": [
        "# MongoDB setup\n",
        "client = pymongo.MongoClient(\"mongodb+srv://bhavyanayak830:hpecppguys@cluster0.k0b3rqz.mongodb.net/\")\n",
        "db = client[\"storage_simulation\"]\n",
        "collection = db[\"usage_logs\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nOQxMu-g3AbO"
      },
      "outputs": [],
      "source": [
        "def load_data(directory=\"/scratch\"):\n",
        "    \"\"\"Load storage data for a specific directory from MongoDB\"\"\"\n",
        "    cursor = collection.find({\"directory\": directory})\n",
        "    df = pd.DataFrame(list(cursor))\n",
        "\n",
        "    # Basic preprocessing\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df = df.sort_values('timestamp')\n",
        "    df = df.drop_duplicates(subset=[\"timestamp\", \"directory\"])\n",
        "    if '_id' in df.columns:\n",
        "        df = df.drop(columns=['_id'])\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def aggregate_to_daily(df):\n",
        "    \"\"\"Aggregate 15-minute data to daily data\"\"\"\n",
        "    # Set timestamp as index and resample to daily frequency\n",
        "    df_daily = df.set_index('timestamp').resample('D').agg({\n",
        "        'storage_gb': 'last',          # Last storage value of the day\n",
        "        'added_gb': 'sum',             # Total added during the day\n",
        "        'deleted_gb': 'sum',           # Total deleted during the day\n",
        "        'updated_gb': 'sum'            # Total updated during the day\n",
        "    }).reset_index()\n",
        "\n",
        "    return df_daily"
      ],
      "metadata": {
        "id": "MjDNaH99IFBP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(data, seq_length):\n",
        "    \"\"\"Create sequences for LSTM input\"\"\"\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X.append(data[i:i+seq_length])\n",
        "        y.append(data[i+seq_length])\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "midA3UwVIHN7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_multistep_sequences(data, input_seq_length, output_seq_length):\n",
        "    \"\"\"Create sequences for multi-step LSTM prediction\"\"\"\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - input_seq_length - output_seq_length + 1):\n",
        "        X.append(data[i:i+input_seq_length])\n",
        "        y.append(data[i+input_seq_length:i+input_seq_length+output_seq_length])\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "7wgvDyXjIJfd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(y_true, y_pred, scaler=None):\n",
        "    \"\"\"Calculate performance metrics\"\"\"\n",
        "    if scaler:\n",
        "        # Reshape data if needed\n",
        "        y_true_reshaped = y_true.reshape(-1, 1) if len(y_true.shape) == 1 else y_true\n",
        "        y_pred_reshaped = y_pred.reshape(-1, 1) if len(y_pred.shape) == 1 else y_pred\n",
        "\n",
        "        # Inverse transform if scaler provided\n",
        "        y_true = scaler.inverse_transform(y_true_reshaped)\n",
        "        y_pred = scaler.inverse_transform(y_pred_reshaped)\n",
        "\n",
        "    # Calculate metrics\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "    return {\n",
        "        'MSE': mse,\n",
        "        'RMSE': rmse,\n",
        "        'MAE': mae,\n",
        "        'R2': r2\n",
        "    }"
      ],
      "metadata": {
        "id": "fvrFRLb7IMQu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(actual, predicted, title):\n",
        "    \"\"\"Plot actual vs predicted values\"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(actual, label='Actual')\n",
        "    plt.plot(predicted, label='Predicted')\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "5CLomp2LIPS_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------ LSTM Models ------------------\n",
        "def build_lstm_model(input_shape, output_shape=1):\n",
        "    \"\"\"Build and compile an LSTM model\"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=input_shape))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(50, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(output_shape))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model"
      ],
      "metadata": {
        "id": "O0_v792aIRcN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------- 15-Minute Prediction Model ---------------\n",
        "def train_15min_model(df, seq_length=96, test_split=0.2):\n",
        "    \"\"\"Train LSTM model for 15-minute predictions\"\"\"\n",
        "    # Prepare data\n",
        "    data = df['storage_gb'].values.reshape(-1, 1)\n",
        "\n",
        "    # Normalize data\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "    # Create sequences\n",
        "    X, y = create_sequences(scaled_data, seq_length)\n",
        "\n",
        "    # Split into train and test sets\n",
        "    train_size = int(len(X) * (1 - test_split))\n",
        "    X_train, X_test = X[:train_size], X[train_size:]\n",
        "    y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "    # Create validation set from training data\n",
        "    val_size = int(len(X_train) * 0.2)\n",
        "    X_val, y_val = X_train[-val_size:], y_train[-val_size:]\n",
        "    X_train, y_train = X_train[:-val_size], y_train[:-val_size]\n",
        "\n",
        "    # Build and train model\n",
        "    model = build_lstm_model((seq_length, 1))\n",
        "\n",
        "    # Early stopping to prevent overfitting\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=100,\n",
        "        batch_size=32,\n",
        "        validation_data=(X_val, y_val),\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Make predictions\n",
        "    train_predictions = model.predict(X_train)\n",
        "    val_predictions = model.predict(X_val)\n",
        "    test_predictions = model.predict(X_test)\n",
        "\n",
        "    # Evaluate model\n",
        "    print(\"\\n--- 15-Minute Model Performance ---\")\n",
        "\n",
        "    # Training metrics\n",
        "    train_metrics = evaluate_model(y_train, train_predictions, scaler)\n",
        "    print(\"Training Metrics:\")\n",
        "    for metric, value in train_metrics.items():\n",
        "        print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "    # Validation metrics\n",
        "    val_metrics = evaluate_model(y_val, val_predictions, scaler)\n",
        "    print(\"\\nValidation Metrics:\")\n",
        "    for metric, value in val_metrics.items():\n",
        "        print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "    # Test metrics\n",
        "    test_metrics = evaluate_model(y_test, test_predictions, scaler)\n",
        "    print(\"\\nTest Metrics:\")\n",
        "    for metric, value in test_metrics.items():\n",
        "        print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "    # Check for overfitting\n",
        "    train_loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(train_loss, label='Training Loss')\n",
        "    plt.plot(val_loss, label='Validation Loss')\n",
        "    plt.title('Training vs Validation Loss (15-Minute Model)')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Plot predictions\n",
        "    # Inverse transform predictions for visualization\n",
        "    y_test_inv = scaler.inverse_transform(y_test)\n",
        "    test_predictions_inv = scaler.inverse_transform(test_predictions)\n",
        "\n",
        "    plot_predictions(y_test_inv, test_predictions_inv, 'Actual vs Predicted (15-Minute Horizon)')\n",
        "\n",
        "    return model, scaler, seq_length, test_metrics"
      ],
      "metadata": {
        "id": "pl-asi8AITgw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------- Daily Prediction Models ---------------\n",
        "def train_daily_model(df_daily, seq_length=30, forecast_horizon=1):\n",
        "    \"\"\"Train LSTM model for daily predictions with specified forecast horizon\"\"\"\n",
        "    # Prepare data\n",
        "    data = df_daily['storage_gb'].values.reshape(-1, 1)\n",
        "\n",
        "    # Normalize data\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "    # Split into train, validation and test sets (60%, 20%, 20%)\n",
        "    train_size = int(len(scaled_data) * 0.6)\n",
        "    val_size = int(len(scaled_data) * 0.2)\n",
        "\n",
        "    train_data = scaled_data[:train_size]\n",
        "    val_data = scaled_data[train_size:train_size+val_size]\n",
        "    test_data = scaled_data[train_size+val_size:]\n",
        "\n",
        "    # For single step prediction\n",
        "    if forecast_horizon == 1:\n",
        "        # Create sequences\n",
        "        X_train, y_train = create_sequences(train_data, seq_length)\n",
        "        X_val, y_val = create_sequences(val_data, seq_length)\n",
        "        X_test, y_test = create_sequences(test_data, seq_length)\n",
        "\n",
        "        # Build and train model\n",
        "        model = build_lstm_model((seq_length, 1))\n",
        "\n",
        "    else:\n",
        "        # Direct multi-step prediction (non-recursive)\n",
        "        X_train, y_train = create_multistep_sequences(train_data, seq_length, forecast_horizon)\n",
        "        X_val, y_val = create_multistep_sequences(val_data, seq_length, forecast_horizon)\n",
        "        X_test, y_test = create_multistep_sequences(test_data, seq_length, forecast_horizon)\n",
        "\n",
        "        # Build and train model for multi-step output\n",
        "        model = build_lstm_model((seq_length, 1), forecast_horizon)\n",
        "\n",
        "    # Early stopping to prevent overfitting\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=15,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=100,\n",
        "        batch_size=16,\n",
        "        validation_data=(X_val, y_val),\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Make predictions\n",
        "    train_predictions = model.predict(X_train)\n",
        "    val_predictions = model.predict(X_val)\n",
        "    test_predictions = model.predict(X_test)\n",
        "\n",
        "    # For multi-step predictions, reshape predictions for evaluation\n",
        "    if forecast_horizon > 1:\n",
        "        y_train_reshaped = y_train.reshape(y_train.shape[0], forecast_horizon)\n",
        "        y_val_reshaped = y_val.reshape(y_val.shape[0], forecast_horizon)\n",
        "        y_test_reshaped = y_test.reshape(y_test.shape[0], forecast_horizon)\n",
        "    else:\n",
        "        y_train_reshaped = y_train\n",
        "        y_val_reshaped = y_val\n",
        "        y_test_reshaped = y_test\n",
        "\n",
        "    # Evaluate model\n",
        "    horizon_desc = \"1 day\" if forecast_horizon == 1 else f\"{forecast_horizon} days\"\n",
        "    print(f\"\\n--- Daily Model Performance ({horizon_desc} horizon) ---\")\n",
        "\n",
        "    # Training metrics\n",
        "    train_metrics = evaluate_model(y_train_reshaped, train_predictions)\n",
        "    print(\"Training Metrics:\")\n",
        "    for metric, value in train_metrics.items():\n",
        "        print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "    # Validation metrics\n",
        "    val_metrics = evaluate_model(y_val_reshaped, val_predictions)\n",
        "    print(\"\\nValidation Metrics:\")\n",
        "    for metric, value in val_metrics.items():\n",
        "        print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "    # Test metrics\n",
        "    test_metrics = evaluate_model(y_test_reshaped, test_predictions)\n",
        "    print(\"\\nTest Metrics:\")\n",
        "    for metric, value in test_metrics.items():\n",
        "        print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "    # Check for overfitting\n",
        "    train_loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(train_loss, label='Training Loss')\n",
        "    plt.plot(val_loss, label='Validation Loss')\n",
        "    plt.title(f'Training vs Validation Loss (Daily Model - {horizon_desc} horizon)')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Plot predictions for the test set\n",
        "    # For multi-step, we'll plot only the first test case as example\n",
        "    if forecast_horizon > 1:\n",
        "        # Take first test example\n",
        "        y_first_test = y_test_reshaped[0]\n",
        "        pred_first_test = test_predictions[0]\n",
        "\n",
        "        # Inverse transform\n",
        "        y_first_test_inv = scaler.inverse_transform(y_first_test.reshape(-1, 1)).flatten()\n",
        "        pred_first_test_inv = scaler.inverse_transform(pred_first_test.reshape(-1, 1)).flatten()\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(range(forecast_horizon), y_first_test_inv, label='Actual')\n",
        "        plt.plot(range(forecast_horizon), pred_first_test_inv, label='Predicted')\n",
        "        plt.title(f'Direct Multi-Step Prediction - {horizon_desc} (First Test Case)')\n",
        "        plt.xlabel('Days ahead')\n",
        "        plt.ylabel('Storage (GB)')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "    else:\n",
        "        # For single step, use the regular plot function\n",
        "        y_test_inv = scaler.inverse_transform(y_test_reshaped)\n",
        "        test_predictions_inv = scaler.inverse_transform(test_predictions)\n",
        "\n",
        "        plot_predictions(y_test_inv, test_predictions_inv, f'Actual vs Predicted (Daily - {horizon_desc} horizon)')\n",
        "\n",
        "    return model, scaler, test_metrics"
      ],
      "metadata": {
        "id": "ps2Gk4rJIZa2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------- Recursive Multi-Step Forecast ---------------\n",
        "def recursive_forecast(model, initial_sequence, scaler, steps, seq_length):\n",
        "    \"\"\"Make recursive multi-step predictions\"\"\"\n",
        "    current_sequence = initial_sequence.copy()\n",
        "    predictions = []\n",
        "\n",
        "    for _ in range(steps):\n",
        "        # Reshape for prediction\n",
        "        current_input = current_sequence[-seq_length:].reshape(1, seq_length, 1)\n",
        "\n",
        "        # Predict next value\n",
        "        next_pred = model.predict(current_input)[0, 0]\n",
        "\n",
        "        # Add prediction to results\n",
        "        predictions.append(next_pred)\n",
        "\n",
        "        # Update sequence for next prediction (rolling window)\n",
        "        current_sequence = np.append(current_sequence, next_pred)\n",
        "\n",
        "    # Convert predictions back to original scale\n",
        "    predictions = np.array(predictions).reshape(-1, 1)\n",
        "    predictions_inv = scaler.inverse_transform(predictions)\n",
        "\n",
        "    return predictions_inv.flatten()"
      ],
      "metadata": {
        "id": "SK4pUN3_Ihr_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_recursive_forecast(df_daily, seq_length=30, forecast_horizons=[1, 7, 30, 90]):\n",
        "    \"\"\"Train LSTM model and evaluate recursive forecasting for multiple horizons\"\"\"\n",
        "    # Prepare data\n",
        "    data = df_daily['storage_gb'].values.reshape(-1, 1)\n",
        "\n",
        "    # Normalize data\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "    # Split data\n",
        "    train_size = int(len(scaled_data) * 0.6)\n",
        "    val_size = int(len(scaled_data) * 0.2)\n",
        "\n",
        "    train_data = scaled_data[:train_size]\n",
        "    val_data = scaled_data[train_size:train_size+val_size]\n",
        "    test_data = scaled_data[train_size+val_size:]\n",
        "\n",
        "    # Create sequences for single-step model\n",
        "    X_train, y_train = create_sequences(train_data, seq_length)\n",
        "    X_val, y_val = create_sequences(val_data, seq_length)\n",
        "    X_test, y_test = create_sequences(test_data, seq_length)\n",
        "\n",
        "    # Build and train model\n",
        "    model = build_lstm_model((seq_length, 1))\n",
        "\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=15,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=100,\n",
        "        batch_size=16,\n",
        "        validation_data=(X_val, y_val),\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate base model\n",
        "    test_predictions = model.predict(X_test)\n",
        "    base_metrics = evaluate_model(y_test, test_predictions, scaler)\n",
        "\n",
        "    print(\"\\n--- Recursive Forecasting Performance ---\")\n",
        "    print(\"Base Model (Single-Step) Metrics:\")\n",
        "    for metric, value in base_metrics.items():\n",
        "        print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "    # For each forecast horizon, make recursive predictions\n",
        "    for horizon in forecast_horizons:\n",
        "        print(f\"\\nEvaluating recursive {horizon}-day forecast:\")\n",
        "\n",
        "        # We'll evaluate on multiple starting points from test data\n",
        "        num_evaluation_points = min(5, len(X_test) - horizon)\n",
        "        all_actuals = []\n",
        "        all_preds = []\n",
        "\n",
        "        for i in range(num_evaluation_points):\n",
        "            # Get actual values for this horizon\n",
        "            if i + horizon < len(test_data):\n",
        "                actual_values = test_data[len(X_test[0]) + i:len(X_test[0]) + i + horizon]\n",
        "                actual_values_inv = scaler.inverse_transform(actual_values).flatten()\n",
        "\n",
        "                # Make recursive forecast\n",
        "                initial_sequence = test_data[:len(X_test[0]) + i].flatten()\n",
        "                forecasted_values = recursive_forecast(model, initial_sequence, scaler, horizon, seq_length)\n",
        "\n",
        "                all_actuals.extend(actual_values_inv)\n",
        "                all_preds.extend(forecasted_values)\n",
        "\n",
        "        # Calculate metrics for this horizon\n",
        "        all_actuals = np.array(all_actuals)\n",
        "        all_preds = np.array(all_preds)\n",
        "\n",
        "        metrics = {\n",
        "            'MSE': mean_squared_error(all_actuals, all_preds),\n",
        "            'RMSE': np.sqrt(mean_squared_error(all_actuals, all_preds)),\n",
        "            'MAE': mean_absolute_error(all_actuals, all_preds),\n",
        "            'R2': r2_score(all_actuals, all_preds)\n",
        "        }\n",
        "\n",
        "        print(f\"Recursive {horizon}-day forecast metrics:\")\n",
        "        for metric, value in metrics.items():\n",
        "            print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "        # Plot example forecast (first evaluation point)\n",
        "        initial_sequence = test_data[:len(X_test[0])].flatten()\n",
        "        forecasted_values = recursive_forecast(model, initial_sequence, scaler, horizon, seq_length)\n",
        "\n",
        "        actual_values = test_data[len(X_test[0]):len(X_test[0]) + horizon]\n",
        "        actual_values_inv = scaler.inverse_transform(actual_values).flatten()\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(range(horizon), actual_values_inv, label='Actual')\n",
        "        plt.plot(range(horizon), forecasted_values, label='Recursive Forecast')\n",
        "        plt.title(f'Recursive {horizon}-Day Forecast')\n",
        "        plt.xlabel('Days ahead')\n",
        "        plt.ylabel('Storage (GB)')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    return model, scaler"
      ],
      "metadata": {
        "id": "nqBMf-NjIlLS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------ Compare Recursive vs. Direct Multi-step ------------------\n",
        "def compare_forecasting_approaches(df_daily, seq_length=30, forecast_horizon=7):\n",
        "    \"\"\"Compare recursive vs direct multi-step forecasting\"\"\"\n",
        "    # Prepare data\n",
        "    data = df_daily['storage_gb'].values.reshape(-1, 1)\n",
        "\n",
        "    # Normalize data\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "    # Split data\n",
        "    train_size = int(len(scaled_data) * 0.6)\n",
        "    val_size = int(len(scaled_data) * 0.2)\n",
        "\n",
        "    train_data = scaled_data[:train_size]\n",
        "    val_data = scaled_data[train_size:train_size+val_size]\n",
        "    test_data = scaled_data[train_size+val_size:]\n",
        "\n",
        "    # --- Train single-step model for recursive forecasting ---\n",
        "    X_train_single, y_train_single = create_sequences(train_data, seq_length)\n",
        "    X_val_single, y_val_single = create_sequences(val_data, seq_length)\n",
        "    X_test_single, y_test_single = create_sequences(test_data, seq_length)\n",
        "\n",
        "    single_step_model = build_lstm_model((seq_length, 1))\n",
        "\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=15,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    single_step_model.fit(\n",
        "        X_train_single, y_train_single,\n",
        "        epochs=100,\n",
        "        batch_size=16,\n",
        "        validation_data=(X_val_single, y_val_single),\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # --- Train direct multi-step model ---\n",
        "    X_train_multi, y_train_multi = create_multistep_sequences(train_data, seq_length, forecast_horizon)\n",
        "    X_val_multi, y_val_multi = create_multistep_sequences(val_data, seq_length, forecast_horizon)\n",
        "    X_test_multi, y_test_multi = create_multistep_sequences(test_data, seq_length, forecast_horizon)\n",
        "\n",
        "    multi_step_model = build_lstm_model((seq_length, 1), forecast_horizon)\n",
        "\n",
        "    multi_step_model.fit(\n",
        "        X_train_multi, y_train_multi,\n",
        "        epochs=100,\n",
        "        batch_size=16,\n",
        "        validation_data=(X_val_multi, y_val_multi),\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # --- Make predictions with both models ---\n",
        "    num_comparison_points = min(5, len(X_test_single) - forecast_horizon)\n",
        "\n",
        "    print(f\"\\n--- Comparing Recursive vs Direct Multi-step ({forecast_horizon}-day horizon) ---\")\n",
        "\n",
        "    recursive_metrics_all = {'MSE': [], 'RMSE': [], 'MAE': [], 'R2': []}\n",
        "    direct_metrics_all = {'MSE': [], 'RMSE': [], 'MAE': [], 'R2': []}\n",
        "\n",
        "    for i in range(num_comparison_points):\n",
        "        # Get actual values\n",
        "        actual_values = test_data[len(X_test_single[0]) + i:len(X_test_single[0]) + i + forecast_horizon]\n",
        "        actual_values_inv = scaler.inverse_transform(actual_values).flatten()\n",
        "\n",
        "        # Recursive forecast\n",
        "        initial_sequence = test_data[:len(X_test_single[0]) + i].flatten()\n",
        "        recursive_forecast_values = recursive_forecast(single_step_model, initial_sequence, scaler, forecast_horizon, seq_length)\n",
        "\n",
        "        # Direct multi-step forecast (if available)\n",
        "        if i < len(X_test_multi):\n",
        "            direct_forecast = multi_step_model.predict(X_test_multi[i].reshape(1, seq_length, 1))[0]\n",
        "            direct_forecast_inv = scaler.inverse_transform(direct_forecast.reshape(-1, 1)).flatten()\n",
        "\n",
        "            # Calculate metrics for this point\n",
        "            recursive_metrics = {\n",
        "                'MSE': mean_squared_error(actual_values_inv, recursive_forecast_values),\n",
        "                'RMSE': np.sqrt(mean_squared_error(actual_values_inv, recursive_forecast_values)),\n",
        "                'MAE': mean_absolute_error(actual_values_inv, recursive_forecast_values),\n",
        "                'R2': r2_score(actual_values_inv, recursive_forecast_values)\n",
        "            }\n",
        "\n",
        "            direct_metrics = {\n",
        "                'MSE': mean_squared_error(actual_values_inv, direct_forecast_inv),\n",
        "                'RMSE': np.sqrt(mean_squared_error(actual_values_inv, direct_forecast_inv)),\n",
        "                'MAE': mean_absolute_error(actual_values_inv, direct_forecast_inv),\n",
        "                'R2': r2_score(actual_values_inv, direct_forecast_inv)\n",
        "            }\n",
        "\n",
        "            # Store metrics\n",
        "            for metric in recursive_metrics:\n",
        "                recursive_metrics_all[metric].append(recursive_metrics[metric])\n",
        "                direct_metrics_all[metric].append(direct_metrics[metric])\n",
        "\n",
        "            # Plot comparison for this point\n",
        "            if i == 0:  # Only plot the first point for clarity\n",
        "                plt.figure(figsize=(12, 6))\n",
        "                plt.plot(range(forecast_horizon), actual_values_inv, label='Actual')\n",
        "                plt.plot(range(forecast_horizon), recursive_forecast_values, label='Recursive Forecast')\n",
        "                plt.plot(range(forecast_horizon), direct_forecast_inv, label='Direct Multi-step')\n",
        "                plt.title(f'Recursive vs Direct Multi-step ({forecast_horizon}-day Horizon)')\n",
        "                plt.xlabel('Days ahead')\n",
        "                plt.ylabel('Storage (GB)')\n",
        "                plt.legend()\n",
        "                plt.show()\n",
        "\n",
        "    # Calculate average metrics\n",
        "    recursive_avg_metrics = {metric: np.mean(values) for metric, values in recursive_metrics_all.items()}\n",
        "    direct_avg_metrics = {metric: np.mean(values) for metric, values in direct_metrics_all.items()}\n",
        "\n",
        "    print(\"\\nRecursive Forecasting Average Metrics:\")\n",
        "    for metric, value in recursive_avg_metrics.items():\n",
        "        print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "    print(\"\\nDirect Multi-step Average Metrics:\")\n",
        "    for metric, value in direct_avg_metrics.items():\n",
        "        print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "    # Compare methods\n",
        "    winner = {\n",
        "        'MSE': 'Direct' if direct_avg_metrics['MSE'] < recursive_avg_metrics['MSE'] else 'Recursive',\n",
        "        'RMSE': 'Direct' if direct_avg_metrics['RMSE'] < recursive_avg_metrics['RMSE'] else 'Recursive',\n",
        "        'MAE': 'Direct' if direct_avg_metrics['MAE'] < recursive_avg_metrics['MAE'] else 'Recursive',\n",
        "        'R2': 'Direct' if direct_avg_metrics['R2'] > recursive_avg_metrics['R2'] else 'Recursive'\n",
        "    }\n",
        "\n",
        "    print(\"\\nBetter Approach by Metric:\")\n",
        "    for metric, better in winner.items():\n",
        "        print(f\"{metric}: {better}\")\n",
        "\n",
        "    return single_step_model, multi_step_model, scaler"
      ],
      "metadata": {
        "id": "hSi4C3iAIqEq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------ Main Execution ------------------\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Loading data for /scratch directory...\")\n",
        "    df = load_data(directory=\"/scratch\")\n",
        "    print(f\"Loaded {len(df)} 15-minute records.\")\n",
        "\n",
        "    # 1. Train and evaluate 15-minute model (immediate next point)\n",
        "    print(\"\\n========== 15-Minute Forecasting Model ==========\")\n",
        "    model_15min, scaler_15min, seq_length_15min, metrics_15min = train_15min_model(df)\n",
        "\n",
        "    # 2. Aggregate to daily for longer horizon predictions\n",
        "    print(\"\\nAggregating data to daily frequency...\")\n",
        "    df_daily = aggregate_to_daily(df)\n",
        "    print(f\"Created {len(df_daily)} daily records.\")\n",
        "\n",
        "    # 3. Train and evaluate models for different forecast horizons\n",
        "    print(\"\\n========== Daily Forecasting Models ==========\")\n",
        "\n",
        "    # 3a. Next day prediction (1-day horizon)\n",
        "    model_1day, scaler_1day, metrics_1day = train_daily_model(df_daily, seq_length=30, forecast_horizon=1)\n",
        "\n",
        "    # 3b. Next week prediction (7-day horizon) using direct multi-step\n",
        "    model_7day, scaler_7day, metrics_7day = train_daily_model(df_daily, seq_length=30, forecast_horizon=7)\n",
        "\n",
        "    # 3c. Next month prediction (30-day horizon) using direct multi-step\n",
        "    model_30day, scaler_30day, metrics_30day = train_daily_model(df_daily, seq_length=30, forecast_horizon=30)\n",
        "\n",
        "    # 3d. Next quarter prediction (90-day horizon) using direct multi-step\n",
        "    model_90day, scaler_90day, metrics_90day = train_daily_model(df_daily, seq_length=30, forecast_horizon=90)\n",
        "\n",
        "    # 4. Evaluate recursive forecasting approach\n",
        "    print(\"\\n========== Recursive Forecasting Evaluation ==========\")\n",
        "    model_recursive, scaler_recursive = evaluate_recursive_forecast(\n",
        "        df_daily,\n",
        "        seq_length=30,\n",
        "        forecast_horizons=[1, 7, 30, 90]\n",
        "    )\n",
        "\n",
        "    # 5. Compare recursive vs direct multi-step (for 7-day horizon)\n",
        "    print(\"\\n========== Comparison: Recursive vs Direct Multi-step ==========\")\n",
        "    model_single, model_multi, scaler_compare = compare_forecasting_approaches(\n",
        "        df_daily,\n",
        "        seq_length=30,\n",
        "        forecast_horizon=7\n",
        "    )\n",
        "\n",
        "    print(\"\\n========== All models trained and evaluated successfully ==========\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2TphJUEIu9r",
        "outputId": "48c370be-f559-4f9a-92f3-36517c960710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data for /scratch directory...\n",
            "Loaded 71618 15-minute records.\n",
            "\n",
            "========== 15-Minute Forecasting Model ==========\n",
            "Epoch 1/100\n",
            "\u001b[1m 167/1431\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:22\u001b[0m 113ms/step - loss: 0.0379"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}